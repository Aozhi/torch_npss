{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.wavenet_model import *\n",
    "from data.dataset import NpssDataset\n",
    "import hparams\n",
    "import pyworld as pw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from data.data_util import decode_harmonic\n",
    "from data.preprocess import process_wav\n",
    "\n",
    "fft_size = 2048\n",
    "\n",
    "def load_latest_model_from(mtype, location):\n",
    "\n",
    "    files = [location + \"/\" + f for f in os.listdir(location)]\n",
    "    newest_file = max(files, key=os.path.getctime)\n",
    "    #debug\n",
    "#     if mtype == 0:\n",
    "#         newest_file = 'snapshots/harmonic/harm_800_2019-04-29_12-00-53'\n",
    "    # else:\n",
    "    #     newest_file = '/home/sean/pythonProj/torch_npss/snapshots/aperiodic/ap_server1649'\n",
    "\n",
    "\n",
    "    print(\"load model \" + newest_file)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if mtype == 0:\n",
    "        hparam = hparams.create_harmonic_hparams()\n",
    "    elif mtype == 1:\n",
    "        hparam = hparams.create_aperiodic_hparams()\n",
    "    else:\n",
    "        hparam = hparams.create_vuv_hparams()\n",
    "\n",
    "    model = WaveNetModel(hparam, device).to(device)\n",
    "    states = torch.load(newest_file)\n",
    "    model.load_state_dict(states['state_dict'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_timbre(path, m_type, mx, mn):\n",
    "    load_t = np.load(path).astype(np.double)\n",
    "\n",
    "    load_t = load_t * (mx - mn) + mn\n",
    "    \n",
    "    plt.imshow(np.transpose(load_t), aspect='auto', origin='bottom', interpolation='none')\n",
    "    plt.show()\n",
    "    \n",
    "    decode_sp = decode_harmonic(load_t, fft_size)\n",
    "    if m_type == 1:\n",
    "        decode_sp = pw.decode_aperiodicity(load_t, 32000, fft_size)\n",
    "\n",
    "    return decode_sp\n",
    "\n",
    "\n",
    "#  type 0:harmonic, 1:aperiodic,\n",
    "def generate_timbre(m_type, mx, mn, condition, cat_input=None, init_input=None):\n",
    "    model_path = 'snapshots/harmonic0_0003'\n",
    "    if m_type == 1:\n",
    "        model_path = 'snapshots/aperiodic'\n",
    "    model = load_latest_model_from(m_type, model_path)\n",
    "    raw_gen = model.generate(condition, cat_input, init_input)\n",
    "    sample = raw_gen.transpose(0, 1).cpu().numpy().astype(np.double) * (mx - mn) + mn\n",
    "\n",
    "    plt.imshow(np.transpose(sample), aspect='auto', origin='bottom', interpolation='none')\n",
    "    plt.show()\n",
    "    \n",
    "    decode_sp = None\n",
    "    if m_type == 0:\n",
    "        decode_sp = decode_harmonic(sample, fft_size)\n",
    "    elif m_type == 1:\n",
    "        decode_sp = pw.decode_aperiodicity(sample, 32000, fft_size)\n",
    "\n",
    "    return decode_sp, raw_gen\n",
    "\n",
    "def generate_vuv(condition, cat_input, init_input=None):\n",
    "    model_path = 'snapshots/vuv'\n",
    "    model = load_latest_model_from(2, model_path)\n",
    "    gen = model.generate(condition, cat_input, init_input).squeeze()\n",
    "\n",
    "    return gen.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "\n",
    "def get_ap_cat():\n",
    "\n",
    "    wav_path = 'data/timbre_model/test/sp/nitech_jp_song070_f001_015_sp.npy'\n",
    "\n",
    "    code_sp = np.load(wav_path).astype(np.double)\n",
    "    return torch.Tensor(code_sp).transpose(0, 1)\n",
    "\n",
    "def get_vuv_cat():\n",
    "    wav_path = 'data/timbre_model/test/sp/nitech_jp_song070_f001_015_sp.npy'\n",
    "\n",
    "    code_sp = np.load(wav_path).astype(np.double)\n",
    "    sp_cat = torch.Tensor(code_sp).transpose(0, 1)\n",
    "\n",
    "    wav_path = 'data/timbre_model/test/ap/nitech_jp_song070_f001_015_ap.npy'\n",
    "\n",
    "    code_sp = np.load(wav_path).astype(np.double)\n",
    "    ap_cat = torch.Tensor(code_sp).transpose(0, 1)\n",
    "\n",
    "    cat = torch.cat((ap_cat, sp_cat), 0)\n",
    "    return cat\n",
    "\n",
    "\n",
    "\n",
    "def get_first_input(song_name):\n",
    "\n",
    "    wav_path = 'data/timbre_model/test/sp/nitech_jp_song070_f001_'+song_name+'_sp.npy'\n",
    "    #wav_path = '/home/sean/pythonProj/torch_npss/data/timbre_model/train/ap/nitech_jp_song070_f001_055_ap.npy'\n",
    "\n",
    "    code_sp = np.load(wav_path).astype(np.double)\n",
    "    return torch.Tensor(code_sp).transpose(0, 1)\n",
    "\n",
    "\n",
    "def get_condition(song_name):\n",
    "\n",
    "    c_path = 'data/timbre_model/test/condition/nitech_jp_song070_f001_'+song_name+'_condi.npy'\n",
    "    conditon = np.load(c_path).astype(np.float)\n",
    "    return torch.Tensor(conditon).transpose(0, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model snapshots/harmonic0_0003/harm0_0003_1649_2019-04-30_19-11-32\n",
      "one generating step does take approximately 0.00586141586303711 seconds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-18803865376a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0msong_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'040_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mgen_song\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-18803865376a>\u001b[0m in \u001b[0;36mgen_song\u001b[0;34m(song_name, t, epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#cat_input = get_ap_cat()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#fist_input = get_first_input(song_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_timbre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bottom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9f4d2991d937>\u001b[0m in \u001b[0;36mgenerate_timbre\u001b[0;34m(m_type, mx, mn, condition, cat_input, init_input)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'snapshots/aperiodic'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_latest_model_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mraw_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UserFolder/Sean/torch_npss/model/wavenet_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, conditions, cat_input, init_input)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mx_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_from_CGM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UserFolder/Sean/torch_npss/model/util.py\u001b[0m in \u001b[0;36msample_from_CGM\u001b[0;34m(out, temperature)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0msigmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UserFolder/Sean/torch_npss/model/util.py\u001b[0m in \u001b[0;36mcal_para\u001b[0;34m(out, temperature)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0momega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# cal temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gen_song(song_name, t, epoch):    \n",
    "    [sp_min, sp_max, ap_min, ap_max] = np.load('data/timbre_model/min_max_record.npy')\n",
    "    condi = get_condition(song_name)\n",
    "    #cat_input = get_ap_cat()\n",
    "    #fist_input = get_first_input(song_name)\n",
    "    sp, raw_sp = generate_timbre(0, sp_max, sp_min, condi, None, None)\n",
    "\n",
    "    plt.imshow(np.log(np.transpose(sp)), aspect='auto', origin='bottom', interpolation='none')\n",
    "    plt.show()\n",
    "\n",
    "#     sp1 = load_timbre('data/timbre_model/test/sp/nitech_jp_song070_f001_'+song_name+'_sp.npy', 0, sp_max, sp_min)\n",
    "\n",
    "#     plt.imshow(np.log(np.transpose(sp1)), aspect='auto', origin='bottom', interpolation='none')\n",
    "#     plt.show()\n",
    "####################################################################################################\n",
    "    ap, raw_ap = generate_timbre(1, ap_max, ap_min, condi, raw_sp, None)\n",
    "    \n",
    "    plt.imshow(np.log(np.transpose(ap)), aspect='auto', origin='bottom', interpolation='none')\n",
    "    plt.show()\n",
    "    \n",
    "#     ap1 = load_timbre('data/timbre_model/test/ap/nitech_jp_song070_f001_'+song_name+'_ap.npy', 1, ap_max, ap_min)\n",
    "    \n",
    "#     plt.imshow(np.log(np.transpose(ap1)), aspect='auto', origin='bottom', interpolation='none')\n",
    "#     plt.show()\n",
    "\n",
    "#########################################################################################################\n",
    "    # vuv_cat = get_vuv_cat()\n",
    "    gen_cat = torch.cat((raw_ap, raw_sp), 0)\n",
    "    \n",
    "    vuv = generate_vuv(condi, gen_cat)\n",
    "    plt.plot(vuv)\n",
    "    plt.show()\n",
    "    \n",
    "#     vuv1 = np.load('data/timbre_model/test/vuv/nitech_jp_song070_f001_'+song_name+'_vuv.npy')\n",
    "#     plt.plot(vuv1)\n",
    "#     plt.show()\n",
    "\n",
    "    path = 'data/cut_raw/nitech_jp_song070_f001_'+song_name+'.raw'\n",
    "    _f0, _sp, code_sp, _ap, code_ap = process_wav(path)\n",
    "    # 合成原始语音\n",
    "    synthesized = pw.synthesize(_f0, _sp, _ap, 32000, pw.default_frame_period)\n",
    "    # 1.输出原始语音\n",
    "    sf.write('./data/gen_wav/'+epoch+'epoch_'+t+'_'+song_name+'.wav', synthesized, 32000)\n",
    "\n",
    "song_name = '040_0'\n",
    "t = 'origin_allow0.05'\n",
    "epoch = '00_1650'\n",
    "\n",
    "#gen_song(song_name, t, epoch)\n",
    "\n",
    "for i in range(12):\n",
    "    song_name = '040_'+str(i)\n",
    "    gen_song(song_name, t, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
